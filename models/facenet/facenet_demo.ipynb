{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "from prettytable import PrettyTable\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MODEL_PATH = os.getenv(\"FACENET_ONNX_MODEL\")\n",
    "IMAGES_BASE_DIR = os.getenv(\"IMAGES_BASE_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_path(img):\n",
    "    return os.path.join(IMAGES_BASE_DIR, img)\n",
    "\n",
    "image_files = os.listdir(IMAGES_BASE_DIR)\n",
    "image_paths = [full_path(img) for img in image_files if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# for path in image_lst:\n",
    "#     print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "FaceNet PyTorch, in particular the one we imported from vggface2 has an input of RGB 160,160 and an embedding output of size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 3, 160, 160], [1, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(MODEL_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "input_tensor_name = session.get_inputs()[0].name\n",
    "output_tensor_name = session.get_outputs()[0].name\n",
    "\n",
    "\n",
    "session.get_inputs()[0].shape, session.get_outputs()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "Ensure the input size is met, convert it from BGR to RGB and normalize the pixel values before passing it on to facenet model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (160, 160))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255.0\n",
    "    return image\n",
    "\n",
    "def normalize_embedding(embedding):\n",
    "    return embedding / np.linalg.norm(embedding)\n",
    "\n",
    "def get_face_embedding(image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    result = session.run([output_tensor_name], {input_tensor_name: image})[0]\n",
    "    embedding = result[0]\n",
    "    return normalize_embedding(embedding)\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return np.dot(embedding1, embedding2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [get_face_embedding(path) for path in image_paths]\n",
    "embedding_array = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify results\n",
    "We use cosine similarity as a metric to evaluate our embedding performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      "+-------------------------+-------------------------+-------------------------+------------------------+-----------------------+-------------------+-------------------+-----------------------+------------------------+-----------------------+-------------------+\n",
      "|                         | Aicha_El_Ouafi_0003.jpg | Aicha_El_Ouafi_0001.jpg | Aaron_Peirsol_0001.jpg | Frank_Solich_0001.jpg | Abdullah_0003.jpg | Abdullah_0004.jpg | Frank_Solich_0004.jpg | Aaron_Peirsol_0002.jpg | Frank_Solich_0002.jpg | Abdullah_0002.jpg |\n",
      "+-------------------------+-------------------------+-------------------------+------------------------+-----------------------+-------------------+-------------------+-----------------------+------------------------+-----------------------+-------------------+\n",
      "| Aicha_El_Ouafi_0003.jpg |          1.0000         |          0.8751         |        -0.0327         |         0.1167        |      -0.0617      |      -0.0064      |         0.1630        |        -0.0276         |        -0.0032        |      -0.0017      |\n",
      "| Aicha_El_Ouafi_0001.jpg |          0.8751         |          1.0000         |         0.0177         |         0.0451        |       0.0228      |       0.0516      |         0.0916        |         0.0339         |        -0.1134        |       0.1186      |\n",
      "|  Aaron_Peirsol_0001.jpg |         -0.0327         |          0.0177         |         1.0000         |         0.0802        |      -0.3282      |      -0.3141      |         0.1684        |         0.8633         |         0.1441        |      -0.2660      |\n",
      "|  Frank_Solich_0001.jpg  |          0.1167         |          0.0451         |         0.0802         |         1.0000        |      -0.1811      |      -0.2988      |         0.7841        |        -0.0017         |         0.8442        |      -0.1689      |\n",
      "|    Abdullah_0003.jpg    |         -0.0617         |          0.0228         |        -0.3282         |        -0.1811        |       1.0000      |       0.7797      |        -0.2369        |        -0.2744         |        -0.3387        |       0.7424      |\n",
      "|    Abdullah_0004.jpg    |         -0.0064         |          0.0516         |        -0.3141         |        -0.2988        |       0.7797      |       1.0000      |        -0.2800        |        -0.1430         |        -0.4019        |       0.7703      |\n",
      "|  Frank_Solich_0004.jpg  |          0.1630         |          0.0916         |         0.1684         |         0.7841        |      -0.2369      |      -0.2800      |         1.0000        |         0.1317         |         0.7953        |      -0.1926      |\n",
      "|  Aaron_Peirsol_0002.jpg |         -0.0276         |          0.0339         |         0.8633         |        -0.0017        |      -0.2744      |      -0.1430      |         0.1317        |         1.0000         |         0.0014        |      -0.1370      |\n",
      "|  Frank_Solich_0002.jpg  |         -0.0032         |         -0.1134         |         0.1441         |         0.8442        |      -0.3387      |      -0.4019      |         0.7953        |         0.0014         |         1.0000        |      -0.2972      |\n",
      "|    Abdullah_0002.jpg    |         -0.0017         |          0.1186         |        -0.2660         |        -0.1689        |       0.7424      |       0.7703      |        -0.1926        |        -0.1370         |        -0.2972        |       1.0000      |\n",
      "+-------------------------+-------------------------+-------------------------+------------------------+-----------------------+-------------------+-------------------+-----------------------+------------------------+-----------------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"\"] + [path.split(\"/\")[-1] for path in image_paths]\n",
    "for i, embedding1 in enumerate(embeddings):\n",
    "    row = [image_paths[i].split(\"/\")[-1]]\n",
    "    for embedding2 in embeddings:\n",
    "        similarity = cosine_similarity(embedding1, embedding2)\n",
    "        row.append(f\"{similarity:.4f}\")\n",
    "    table.add_row(row)\n",
    "\n",
    "print(\"Similarity Matrix:\")\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DBScan cluster results\n",
    "Density based clustering algorithm, see scikit learn documentation/Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "  Aicha_El_Ouafi_0003.jpg\n",
      "  Aicha_El_Ouafi_0001.jpg\n",
      "\n",
      "Cluster 1:\n",
      "  Aaron_Peirsol_0001.jpg\n",
      "  Aaron_Peirsol_0002.jpg\n",
      "\n",
      "Cluster 2:\n",
      "  Frank_Solich_0001.jpg\n",
      "  Frank_Solich_0004.jpg\n",
      "  Frank_Solich_0002.jpg\n",
      "\n",
      "Cluster 3:\n",
      "  Abdullah_0003.jpg\n",
      "  Abdullah_0004.jpg\n",
      "  Abdullah_0002.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.6, min_samples=2, metric='cosine')\n",
    "cluster_labels = dbscan.fit_predict(embedding_array)\n",
    "clusters = {}\n",
    "for path, label in zip(image_paths, cluster_labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(path.split(\"/\")[-1])\n",
    "\n",
    "for cluster_id, image_names in clusters.items():\n",
    "    if cluster_id == -1:\n",
    "        print(\"outliers:\")\n",
    "    else:\n",
    "        print(f\"Cluster {cluster_id}:\")\n",
    "    for image_name in image_names:\n",
    "        print(f\"  {image_name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
